{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading configuration file generation_config.json from cache at aitextgen/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aitextgen import aitextgen\n",
    "\n",
    "ai = aitextgen()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.7.0\n",
      "\n",
      "1.9.6.0\n",
      "\n",
      "1.9.5.0\n",
      "\n",
      "1.9.4.0\n",
      "\n",
      "1.9.3.0\n",
      "\n",
      "1.9.2.0\n",
      "\n",
      "1.9.1.0\n",
      "\n",
      "1.9.0.0\n",
      "\n",
      "1.8.4.0\n",
      "\n",
      "1.8.3.0\n",
      "\n",
      "1.8.2.0\n",
      "\n",
      "1.8.1.0\n",
      "\n",
      "1.8.0.0\n",
      "\n",
      "1.7.6.0\n",
      "\n",
      "1.7.5.0\n",
      "\n",
      "1.7.0.0\n",
      "\n",
      "1.7.1.0\n",
      "\n",
      "1.6.9.0\n",
      "\n",
      "1.6.8.0\n",
      "\n",
      "1.6.7.0\n",
      "\n",
      "1.6.6.0\n",
      "\n",
      "1.6.5.0\n",
      "\n",
      "1.6.4.0\n",
      "\n",
      "1.6.3.0\n",
      "\n",
      "1.6.2.0\n",
      "\n",
      "1.6.1.0\n",
      "\n",
      "1.5.9.0\n",
      "\n",
      "1.4.9.0\n",
      "\n",
      "1.4\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m, it is the only place I can find that offers a wide variety of other games. If you have an itch to get something in and you want to play it, I recommend getting it from the store.\n",
      "\n",
      "The game has a beautiful setting and the art is beautiful. The music is really good and the music is also very good. I love the music. The music is nice and the game feels like a great way to learn. The story is very well told but the ending is not good. The ending is not very good either.\n",
      "\n",
      "I bought the game on my first attempt, but after a long time, I came up with a game I like. I also like the story and is very well told. The story is very good and the music is very good. I love the story and is very well told. The game has a beautiful setting and the art is beautiful. The music is really good and the game feels like a great way to learn. The ending is not very good either.\n",
      "\n",
      "I had a difficult time finding a game I like. I could pick up games I like but I don't know if I will. I tried many games and I never had one. I would get a chance to play\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m.\n",
      "\n",
      "Lionel Messi was very good for Everton when he was in the first team.\n",
      "\n",
      "He was a first year player for them and was a big part of their success.\n",
      "\n",
      "The Argentine has had to learn a lot from his time at Porto and Everton.\n",
      "\n",
      "He will play for them once he's back in the club.\n",
      "\n",
      "He is a great player and his skill set is very different to what you see on the pitch.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\", max_length=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m. Just like we love the way we all love roblox. Just like we love the way we all love roblox.\n",
      "==========\n",
      "\u001b[1mI love roblox\u001b[0m, but it's not the same for me. I'm starting to realize that it's possible to be a better person by taking action. I'm not making this up, but I've been around as long as I can remember. I don't know if I could ever be a better person, but I'm going to take action. That's the way I see it.\n",
      "\n",
      "Here's what I'm going to do:\n",
      "\n",
      "I'm going to stand up\n",
      "==========\n",
      "\u001b[1mI love roblox\u001b[0m, I love all of this. I love the amazing team that they have, the support that they have, the support that I've had from my teammates, the great communication, the great support that I've had from my family, the great support that I've had from my friends and family. I don't think I've ever known anything like that. I don't know how to describe it. I think it's so much more than that because I think I need\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\", max_length=100, n=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m we could test what's going on in real-world production, and the whole process would be automated.\n",
      "\n",
      "I'm interested to hear how and why you're using Github copilot.\n",
      "\n",
      "I'm working on a prototype of the copilot. I already know for a fact that the code is very well organized (using a lot of variables, and some of them are really good, but the way this is written is very different for the way you\n",
      "==========\n",
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m it would allow you to build it yourself, and give you a better idea of what you could build.\n",
      "\n",
      "So, if you were able to build this app using git, you could use this tutorial to build it yourself.\n",
      "\n",
      "And if you could build it using git again, you could use the same tutorial to build it again.\n",
      "\n",
      "But, for now, the best way to build this app is to use git to build the app from\n",
      "==========\n",
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m we would be able to build one for the free version of Android, and then add it to our project.\n",
      "\n",
      "Building a website\n",
      "\n",
      "You can build a blog with this tutorial. The idea is that you would create a project that would show you how to create a website and then publish it on your own website.\n",
      "\n",
      "This will serve as a base for our website and get you started with adding a blog to your own website.\n",
      "\n",
      "We\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"Using Github copilot would be useful because\", max_length=100, n=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAre you an A.I?\u001b[0m How about a new favorite?\n",
      "\n",
      "It seems to all but end in a bang-up mess.\n",
      "\n",
      "A.I.s aren't just the new coolness in the picture, but the power to make it look like you're here.\n",
      "\n",
      "Maybe you're a newbie or a longtime fan of the show, but I think it's safe to say you've probably been following the show for some time now.\n",
      "\n",
      "I've spent a bit of time checking out the show and I've come to expect a certain kind of fun and silly fun to come.\n",
      "\n",
      "I've found that the show is truly, truly awesome.\n",
      "\n",
      "I've been following the crew on a daily basis. They're amazing.\n",
      "\n",
      "I've learned a lot about the show.\n",
      "\n",
      "I've learned a lot about what it takes to be a great fan.\n",
      "\n",
      "I've learned a lot about the characters.\n",
      "\n",
      "I've learned a lot about the show's themes.\n",
      "\n",
      "I've learned a lot about the people behind the show.\n",
      "\n",
      "I've learned a lot about the show's relationships.\n",
      "\n",
      "I've learned a lot about the show's world.\n",
      "\n",
      "All the while, I've been\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"Are you an A.I?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_tokenizer('shake.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 86572.38it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = GPT2ConfigCPU()\n",
    "\n",
    "ai = aitextgen(tokenizer_file = \"aitextgen.tokenizer.json\", config=config)\n",
    "\n",
    "data = TokenDataset(\"Shake.txt\", tokenizer_file=\"aitextgen.tokenizer.json\", block_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:466: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loss: 4.340 — Avg: 4.413:  14%|█▍        | 700/5000 [00:44<04:36, 15.57it/s]"
     ]
    }
   ],
   "source": [
    "ai.train(data,batch_size=8,num_steps=5000,generate_every=5000,save_every=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
