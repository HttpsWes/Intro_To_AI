{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading configuration file generation_config.json from cache at aitextgen/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aitextgen import aitextgen\n",
    "\n",
    "ai = aitextgen()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You don't need to make a large amount of money to be a good journalist. But in order to be a good journalist, a lot of people have to be bad.\n",
      "\n",
      "\"Some people are going to make a lot of money and some people are going to make a little bit of money. But I personally feel like I'm not in the best position to tell all those stories and I'm more likely to be in a bad position than I am to be in the best position to tell all those stories.\"\n",
      "\n",
      "Sylvia Huppert, a journalist in New York City, was at the end of her first year in the New York State Assembly when the New York State Assembly passed new laws to make the state's public records laws easier to access.\n",
      "\n",
      "\"The New York Legislature was so hostile to information technology,\" said Huppert, who says she had to use her social media accounts to get a copy of the legislation before it became law. \"I remember the next day, I went to the statehouse to get a copy of the bill and I didn't have a single word of it. It was like, wow, it's a law passed in the legislature. It's totally out of our control.\"\n",
      "\n",
      "Hupp\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m, but I love the idea of the'real' side of me. I always knew that I would be a total dork, but I've never been able to find the courage to admit that I'm actually a dork. \n",
      "1. I've been making this blog for over a decade now, and I can't believe I'm still not done blogging. I've been here for almost a decade now, and I still have so much to write. I've not been able to find the courage to admit I'm actually a dork.\n",
      "2. If I can't do this, I'm going to have to work on the next one. I won't be able to do every single thing I write. I love to write, but I struggle to write. I have to find a new way to write, and I've been doing this for almost a decade now.\n",
      "3. I hate the idea of \"realising\" how hard it is to write an article for a magazine or journal. I've heard so many of these things before, and I knew so many of them would be hard to get around, and I had to find someone to write to. I don't want to live in a world where no\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m, it's such an interesting, awesome app. I like the fact that you can open your app. It's pretty much the same as iOS, you just have to click the little little red icon on the left of the app and it'll open up an app.\n",
      "\n",
      "The problem is in that Apple is in charge of all the things that you can do on your phone and not have to. So, I mean, maybe I'm not going to use a big\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\", max_length=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m.io and it is a great way to learn more about the blockchain technology and the way it works.\"\n",
      "\n",
      "The project is available for download on GitHub at https://github.com/gcc/roblox.io.\n",
      "\n",
      "The project is based on the bitcoin-qt-dev project, which was created by Gregory Maxwell, the creator of the original bitcoin-qt platform.\n",
      "\n",
      "The project was named after the late co-founder and CEO of bitcoin\n",
      "==========\n",
      "\u001b[1mI love roblox\u001b[0m for our first product and it's a great choice for those who like the idea of getting their own product. You can also find roblox in a variety of colors. But, the main reason why I'm not buying roblox is because I want to make sure that my products are safe and pure.\n",
      "\n",
      "There are a few things you can do to minimize the risk of contamination with your roblox product.\n",
      "\n",
      "Try to avoid the very small amount\n",
      "==========\n",
      "\u001b[1mI love roblox\u001b[0m, but if you have any questions or if you have any suggestions for improvement please send me a PM.\n",
      "\n",
      "\n",
      "Thanks!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\", max_length=100, n=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m Github is the only place where you can get your ideas in a timely manner. But it's also important! I feel like the community is pretty good with working out these issues and helping each other out.\n",
      "\n",
      "One thing I have noticed is that I like to spend a lot of time on coding. I have been doing so since I was a kid and I love to read, write, and test stuff. I've been doing this for a while now\n",
      "==========\n",
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m it would let me know if they're working on a good project. The person I'd ask to set up the repo or to build a new project are so different from my fellow copilot that the next time you make a request, you'd be a better match than yours. It would also prove to be a good way to get me started on the project.\n",
      "\n",
      "I also had a chance to talk to a friend of mine at the company who was\n",
      "==========\n",
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m it would be a more concise way to get the user to do things.\n",
      "\n",
      "What you end up doing, when you add the code:\n",
      "\n",
      "$ git checkout https://github.com/kim-paul/tutorial-tutorial-tutorial-tutorial $ git add.\n",
      "\n",
      "The script will also take care of the rest of the details if you need to go completely out of the way.\n",
      "\n",
      "What if I did\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"Using Github copilot would be useful because\", max_length=100, n=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAre you an A.I?\u001b[0m Do you love you?\n",
      "\n",
      "You're ready for the big time.\n",
      "\n",
      "(This is my first post as an A.I.)\n",
      "\n",
      "There's a lot to talk about for this one.\n",
      "\n",
      "But first, I want to say a few things about myself.\n",
      "\n",
      "I've been writing since the age of 17.\n",
      "\n",
      "And I've been writing since the age of 13.\n",
      "\n",
      "Now, I'm 17.\n",
      "\n",
      "I have a job, a home, and a job.\n",
      "\n",
      "I need a car, and I need a house.\n",
      "\n",
      "I've been reading a lot of books.\n",
      "\n",
      "I'm a good teacher.\n",
      "\n",
      "I have a great friend.\n",
      "\n",
      "I'm a good friend of mine.\n",
      "\n",
      "I've done a lot of things for myself and for my family.\n",
      "\n",
      "I have a real job in life.\n",
      "\n",
      "I've been a successful athlete.\n",
      "\n",
      "I have a home.\n",
      "\n",
      "My son is a good kid.\n",
      "\n",
      "I am an A.I.\n",
      "\n",
      "And I've got a great, hardworking family.\n",
      "\n",
      "I've got a great life.\n",
      "\n",
      "And I do everything I can to help the A.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"Are you an A.I?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_tokenizer('shake.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 90831.71it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = GPT2ConfigCPU()\n",
    "\n",
    "ai = aitextgen(tokenizer_file = \"aitextgen.tokenizer.json\", config=config)\n",
    "\n",
    "data = TokenDataset(\"Shake.txt\", tokenizer_file=\"aitextgen.tokenizer.json\", block_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:466: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m                  \n",
      "Loss: 3.420 — Avg: 3.479: 100%|██████████| 5000/5000 [03:59<00:00, 20.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in trained_model/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m                        \n",
      "Loss: 3.420 — Avg: 3.479: 100%|██████████| 5000/5000 [03:59<00:00, 20.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========                                                                   \n",
      ":                                                                            \n",
      "He methitew my life'sting, or lady\n",
      "Because; or I would laud it not so,\n",
      "Be it was so.\n",
      "\n",
      "BUCKINGHAM:\n",
      "If you would I for for it delited.\n",
      "\n",
      "F\n",
      "==========                                                                   \n",
      "Loss: 3.420 — Avg: 3.479: 100%|██████████| 5000/5000 [03:59<00:00, 20.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.420 — Avg: 3.479: 100%|██████████| 5000/5000 [03:59<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in trained_model/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "ai.train(data,batch_size=8,num_steps=5000,generate_every=5000,save_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mROMEO:\u001b[0m\n",
      "GORY, thou know to say'st a son?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Against my noble lord,\n",
      "It dost you, to our master,\n",
      "Wherein this is my son is the king,\n",
      "I am for the wastle of youth,\n",
      "\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "It is my son,\n",
      "Are this good pasts of me.\n",
      "\n",
      "POLIXENES:\n",
      "Well, geteraliers!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "What will say, my father's death.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "But, and st\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "'ld 'twas, my brother Wood my brother,\n",
      "And methoms the prince I borning\n",
      "To budgree of his father's face,\n",
      "Upon it shall.\n",
      "\n",
      "\n",
      "First Murderer:\n",
      "O\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Had, the prince I may be told.'\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "I wish thee from him from me.\n",
      "\n",
      "RIANCA:\n",
      "Have you more?\n",
      "\n",
      "BIONBRUTUS:\n",
      "Nit\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "This is my lord beasting the breathementd in the prince\n",
      "Though she glorives and we might be notself.\n",
      "Whom the king's death of thy heart.\n",
      "Ah, madam, for the boad,\n",
      "Are\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "From my good master, the father's chophind of him,\n",
      "But in thy bounds together and his bested and hour;\n",
      "And, morneem the triond of his king,\n",
      "And that you shall deter\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "This is your graces?\n",
      "\n",
      "HENRY BOLINGBERLAND:\n",
      "Why, sir, he did?\n",
      "\n",
      "KING RICHARD III:\n",
      "I am told him, and every.\n",
      "\n",
      "FRIRANIA:\n",
      "A good Caliolia\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "O God, do you, of this be your highness\n",
      "miss of some pute: lest I do,\n",
      "But, a valiity and borne the duke of the genererar\n",
      "From thy rewards in the stop\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "I cuit you do not.\n",
      "\n",
      "KATHARINA:\n",
      "One!\n",
      "NORIZA:\n",
      "I do not another sea.\n",
      "\n",
      "CAMILLO:\n",
      "Fie, if you so.\n",
      "\n",
      "ISABELLA:\n",
      "These is\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "I will lear you must be so.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Will, and bark in my son I did no fonder\n",
      "Wherein that he must less the king\n",
      "And to the world of his churb,\n",
      "And chang\n"
     ]
    }
   ],
   "source": [
    "ai.generate(10 ,prompt=\"ROMEO:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
