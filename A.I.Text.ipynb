{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading configuration file generation_config.json from cache at aitextgen/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aitextgen import aitextgen\n",
    "\n",
    "ai = aitextgen()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Stephen MacLean\n",
      "\n",
      "For nearly a century, a former Army officer has been a fixture of the national consciousness and, today, he is a fixture of the international debate over the issue.\n",
      "\n",
      "At a time when global warming is a national security threat, his presence is a highlight of the international press coverage. So he is a huge deal.\n",
      "\n",
      "But now he's been a bit of a surprise.\n",
      "\n",
      "Mr. MacLean, a former Army officer who served for four years in Afghanistan, was interviewed on ABC's This Week. He had just finished his last year at West Point and he was interviewing his new boss.\n",
      "\n",
      "\"When I got to the last part of that interview, you said, 'You're a veteran of service', and I said, 'Yes, I've been an officer in the Army for nine years.'\" Mr. MacLean said. \"Well, I started out as a sergeant, and I'm always open to talking about the military and about my experience, and I wanted to talk to you about the military.\"\n",
      "\n",
      "Mr. MacLean, who was born in Canada, now works as a special project manager for the US Army's Global Affairs Office.\n",
      "\n",
      "Mr. MacLean said he grew up\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m so much.\"\n",
      "\n",
      "The two had been friends for most of their lives though, and had met when he was a junior at a school in the United Kingdom. As he was leaving, he noticed something odd, and ran to the door: \"Are you there?\"\n",
      "\n",
      "\"I am,\" he answered, and put his hand on his cheek.\n",
      "\n",
      "\"Hey, are you home?\"\n",
      "\n",
      "\"No, I am out with my friends.\"\n",
      "\n",
      "\"Are your friends going to come over here?\"\n",
      "\n",
      "\"No, they are not. I am going to go for a walk. I am very happy here.\"\n",
      "\n",
      "They went to a park and walked to the edge of the field on the edge of the woods, and he saw a young man with a beard and a beard and a beard, and they were going to meet, and he told them he'd come to make things right.\n",
      "\n",
      "\"I don't know why you don't want him.\"\n",
      "\n",
      "\"Why not?\"\n",
      "\n",
      "\"Because he's going to help me out with a problem,\" he said, \"but I'm going to come for him. I'm going to go for him. I'm going to go for him. I want\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m, it's a great tool to show time to yourself and what you're doing. I have been on a lot of projects and I'm just trying to keep this thing going. I'm learning. I'm getting better at it. My goal with roblox is to build a tool for my home project. I've been in the market for a few years now and I always knew this would be an interesting tool to use. I'm trying to build a tool that\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\", max_length=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mI love roblox\u001b[0m and it's my first time using her. My first time using it was on my first day of school and it was so easy to use it. I love her work and love how easy she is to use. I'm in love with the way she does things. I'm a big fan of the way she makes the food, and I'm excited to see what she does with the rest of her creations. I'm really excited to see how much she gets out of\n",
      "==========\n",
      "\u001b[1mI love roblox\u001b[0m, it's like going to a hotel with an old man and it's like, \"Oh, well, I'm at this hotel and I'm gonna make a lot of money and I'm gonna get really high, and I'm going to show you my face and my face and my face on the street, and I'm gonna see you around the corner.\" So I just wanted to make that happen.\" The one thing I did was, I went and got a guy\n",
      "==========\n",
      "\u001b[1mI love roblox\u001b[0m and i love this game. It is a dream come true. I will try to keep playing it and I have tried to do so for days.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"I love roblox\", max_length=100, n=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m he could easily get some data to look at on Github. There are a lot of tools out there that can be used to do this sort of thing and it's great how many people have started using it and it's great how many people have decided to use it and they're not just using it to get a better understanding of what they're doing.\n",
      "\n",
      "It's hard to say when to use it but I think it's great for learning about your\n",
      "==========\n",
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m you can make a small contribution. You would also be able to make a contribution to the community as a volunteer and give to other people who need help.\n",
      "\n",
      "How to do this\n",
      "\n",
      "Here are some general questions you should ask yourself before committing to a project:\n",
      "\n",
      "Do you have good connections with existing developers or projects?\n",
      "\n",
      "Do you have good technical backgrounds?\n",
      "\n",
      "Do you have a team of the people who are making the project?\n",
      "==========\n",
      "\u001b[1mUsing Github copilot would be useful because\u001b[0m it would allow us to quickly deploy to any server, without having to start over from scratch.\n",
      "\n",
      "We're currently using the server at the GitHub Cloud Store.\n",
      "\n",
      "The server will be deployed to the GitHub Cloud Store by adding the following code to our project:\n",
      "\n",
      "import React from'react'; import {BuildComponent} from'react-dom'; export default build({ props: 'buildComponent' }); 1 2 3 4 5 6 import React\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"Using Github copilot would be useful because\", max_length=100, n=3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAre you an A.I?\u001b[0m\n",
      "\n",
      "In 2011, a team of scientists led by Professor Mark D. Anderson at the University of Minnesota led by Professor David K. Kullman of the University of California, Irvine, examined the effects of antibiotics on human colon cancer cells. They found that the bacteria found in the colon were less likely to cause cancer. The team's findings were presented today at the American Cancer Society Annual Meeting in San Francisco.\n",
      "\n",
      "\"When antibiotics are taken to treat cancer, they have a positive effect on many parts of the body,\" says Anderson. \"But when antibiotics are used to treat human cancer cells, they have a negative effect on other parts of the body.\"\n",
      "\n",
      "In the study, the researchers found that bacteria that were found in the colon had more activity in the colon cells and are less likely to die. However, the bacteria that were found in the colon had a higher rate of colon cancer compared to the bacteria that were found in the colon.\n",
      "\n",
      "The team is currently working on the next steps to find out if this is the case in humans. \"The next step is to see if antibiotics are more effective at treating many aspects of cancer,\" says Anderson. \"The next step is to see if antibiotics are effective at treating\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ai.generate(prompt=\"Are you an A.I?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_tokenizer('shake.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:00<00:00, 82129.29it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = GPT2ConfigCPU()\n",
    "\n",
    "ai = aitextgen(tokenizer_file = \"aitextgen.tokenizer.json\", config=config)\n",
    "\n",
    "data = TokenDataset(\"Shake.txt\", tokenizer_file=\"aitextgen.tokenizer.json\", block_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:466: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ECU/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m                  \n",
      "Loss: 3.450 — Avg: 3.474: 100%|██████████| 5000/5000 [03:25<00:00, 24.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in trained_model/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m                        \n",
      "Loss: 3.450 — Avg: 3.474: 100%|██████████| 5000/5000 [03:25<00:00, 24.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========                                                                   \n",
      " and divish mind,                                                            \n",
      "And every len's woe, and as\n",
      "Sthat, a so throng is woful in a world,\n",
      "Hisclaute, and seem, or a broatt\n",
      "Nerect\n",
      "==========                                                                   \n",
      "Loss: 3.450 — Avg: 3.474: 100%|██████████| 5000/5000 [03:25<00:00, 24.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.450 — Avg: 3.474: 100%|██████████| 5000/5000 [03:25<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in trained_model/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "ai.train(data,batch_size=8,num_steps=5000,generate_every=5000,save_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mROMEO:\u001b[0m\n",
      "What's the messeny;\n",
      "What's this is the senits, to the freely?\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Good Roman, you be sense of Warwick,\n",
      "I'll feel his soul is to\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "For thou shalt not be near on,\n",
      "Mad thou wilt, boy'd of our courts.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "'night, then, gods, drink'd, let them fore\n",
      "In the eat\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "O, and the lastard, to the victors,\n",
      "And in a brazardensom; or even gates,\n",
      "But thus I will not recove my seve,\n",
      "You have no lady'd:\n",
      "A haff\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Lay me peace and,\n",
      "That we have it so much, my indeed, to be sever to the\n",
      "hore than the body of his own tears: who, this sholdert.\n",
      "\n",
      "First Murderer:\n",
      "No,\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "His a glory, and lettern\n",
      "Have he had fly; a man;\n",
      "For they must woes one and body.\n",
      "\n",
      "POMPEY:\n",
      "Say, thou talk.\n",
      "\n",
      "LEONTES:\n",
      "A\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "I have been with you.\n",
      "\n",
      "ROMEO:\n",
      "Tru, good hourour porture of the coect\n",
      "Dally voice, to strike.\n",
      "\n",
      "PROS:\n",
      "And you to the time, sir!\n",
      "\n",
      "QUEEN:\n",
      "G\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "What is you moved.\n",
      "\n",
      "MARCIUS:\n",
      "Sir, I know the rest; I must be resolved,\n",
      "You will not subject my tuty.\n",
      "\n",
      "FORIAR LAURENCE:\n",
      "Sir\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Tell, that can I have been louded my mind\n",
      "Of cozest; and pain a banish'd,\n",
      "And here's to the oathsclised, and ref\n",
      "Which I have been accuing of thy heart:\n",
      "\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Would not be a slow: this day,\n",
      "O, that dost thou not believed, the distress\n",
      "Tyoubt and be sovereigns to the time.\n",
      "\n",
      "BRUTUS:\n",
      "He shall not this be seem\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "You crup to take what you go to-morrow.\n",
      "\n",
      "SICINIUS:\n",
      "Tell, I'll wo yours.\n",
      "\n",
      "PROSPERO:\n",
      "Nay, let me.\n",
      "\n",
      "AUTOLYCLIENCHERD:\n"
     ]
    }
   ],
   "source": [
    "ai.generate(10 ,prompt=\"ROMEO:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
